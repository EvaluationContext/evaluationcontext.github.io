{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xmltodict\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XML to dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "EventSubClass ={\n",
    "    1: 'logical',\n",
    "    2: 'physical'\n",
    "}\n",
    "queries = {}\n",
    "\n",
    "with open('trace.xml', encoding='utf-16') as fd:\n",
    "    queryPlan = xmltodict.parse(fd.read(), encoding='utf-16')\n",
    "\n",
    "for event in queryPlan['TraceData']['Events']['Event']:\n",
    "    if event['@name'] == 'DAX Query Plan':\n",
    "        \n",
    "        for column in event['Column']:\n",
    "            \n",
    "            if column['@name'] == 'TextData':\n",
    "                query = column['#text']\n",
    "    \n",
    "            if column['@name'] == 'EventSubclass':\n",
    "                queryType = EventSubClass[int(column['#text'])]\n",
    "    \n",
    "        queries[queryType] = query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_records(line) -> int:\n",
    "    match = re.search(r'#Records=(\\d+)', line)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    return None\n",
    "\n",
    "def extract_operation_type(line) -> list:\n",
    "    match = re.search(r'(.*): (\\w*)', line)\n",
    "    if match:\n",
    "        return [match.group(1).strip(), match.group(2).strip()]\n",
    "    return None\n",
    "\n",
    "def generate_graph(lines: list)->list:\n",
    "    stack = []\n",
    "    level_parents = {}\n",
    "    graph = []\n",
    "\n",
    "    for index, line in enumerate(lines):\n",
    "        current_level = len(line) - len(line.lstrip())\n",
    "        \n",
    "        while len(stack) > current_level:\n",
    "            stack.pop()\n",
    "        \n",
    "        parent_index = level_parents.get(current_level - 1, None)\n",
    "        \n",
    "        stack.append((index, line))\n",
    "        \n",
    "        level_parents[current_level] = index\n",
    "\n",
    "        operationType = extract_operation_type(line)\n",
    "\n",
    "        graph.append({\n",
    "            'srcid': parent_index,\n",
    "            'dstid': index,\n",
    "            'operation': line.strip(),\n",
    "            'operationShort': operationType[0],\n",
    "            'operationType': operationType[1],\n",
    "            'isCache': operationType[0] == 'Cache',\n",
    "            'level': current_level,\n",
    "            'records': extract_records(line)\n",
    "        })\n",
    "    \n",
    "    return graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RelLogOp\n",
      "RelLogOp\n",
      "RelLogOp\n",
      "ScaLogOp\n",
      "ScaLogOp\n",
      "ScaLogOp\n",
      "ScaLogOp\n",
      "ScaLogOp\n",
      "ScaLogOp\n",
      "RelLogOp\n",
      "RelLogOp\n",
      "ScaLogOp\n",
      "ScaLogOp\n",
      "RelLogOp\n",
      "RelLogOp\n",
      "RelLogOp\n",
      "RelLogOp\n",
      "RelLogOp\n",
      "ScaLogOp\n",
      "ScaLogOp\n",
      "ScaLogOp\n",
      "ScaLogOp\n",
      "ScaLogOp\n",
      "ScaLogOp\n",
      "ScaLogOp\n",
      "IterPhyOp\n",
      "IterPhyOp\n",
      "SpoolPhyOp\n",
      "IterPhyOp\n",
      "IterPhyOp\n",
      "IterPhyOp\n",
      "IterPhyOp\n",
      "SpoolPhyOp\n",
      "IterPhyOp\n",
      "IterPhyOp\n",
      "SpoolPhyOp\n",
      "IterPhyOp\n",
      "IterPhyOp\n",
      "SpoolPhyOp\n",
      "IterPhyOp\n",
      "LookupPhyOp\n",
      "LookupPhyOp\n",
      "SpoolPhyOp\n",
      "IterPhyOp\n",
      "SpoolPhyOp\n",
      "IterPhyOp\n",
      "IterPhyOp\n",
      "SpoolPhyOp\n",
      "IterPhyOp\n",
      "IterPhyOp\n",
      "IterPhyOp\n",
      "IterPhyOp\n",
      "SpoolPhyOp\n",
      "IterPhyOp\n",
      "IterPhyOp\n",
      "SpoolPhyOp\n",
      "IterPhyOp\n",
      "LookupPhyOp\n",
      "LookupPhyOp\n",
      "LookupPhyOp\n",
      "LookupPhyOp\n",
      "LookupPhyOp\n",
      "LookupPhyOp\n",
      "LookupPhyOp\n",
      "LookupPhyOp\n"
     ]
    }
   ],
   "source": [
    "graphs = {}\n",
    "\n",
    "for queryType, query in queries.items():\n",
    "\n",
    "    graphs[queryType] = generate_graph(lines = query.split('\\n'))\n",
    "\n",
    "with open('queryPlan.json', 'w') as fp:\n",
    "    json.dump(graphs, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
